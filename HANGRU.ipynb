{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU, Bidirectional, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn import preprocessing as skpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/cleaned_lyrics_newlines_included.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0   index                                               song  \\\n",
      "0                0       0                                          ego-remix   \n",
      "1                1       1                                       then-tell-me   \n",
      "2                2       2                                            honesty   \n",
      "3                3       3                                    you-are-my-rock   \n",
      "4                4       4                                      black-culture   \n",
      "5                5       5                             all-i-could-do-was-cry   \n",
      "6                6       6                                 once-in-a-lifetime   \n",
      "7                7       7                                            waiting   \n",
      "8                8       8                                          slow-love   \n",
      "9                9       9                              why-don-t-you-love-me   \n",
      "10              10      10                                      save-the-hero   \n",
      "11              11      11                                          telephone   \n",
      "12              12      12                                    ice-cream-truck   \n",
      "13              13      13                             no-broken-hearted-girl   \n",
      "14              14      14                                            control   \n",
      "15              15      15                                      i-m-alone-now   \n",
      "16              16      16                                             poison   \n",
      "17              17      17                                   world-wide-women   \n",
      "18              18      18                                     beautiful-liar   \n",
      "19              19      19                             beautiful-liar-spanish   \n",
      "20              20      20                   beautiful-liar-spanglish-version   \n",
      "21              21      21                                          bienvenue   \n",
      "22              22      22                                beutiful-liar-remix   \n",
      "23              23      23  he-still-loves-me-f-choir-from-fighting-tempta...   \n",
      "24              24      24                                    bello-embustero   \n",
      "25              25      25                                         irreplable   \n",
      "26              26      26                                      the-first-day   \n",
      "27              27      27                                             my-man   \n",
      "28              28      28                                 what-s-it-gonna-be   \n",
      "29              29      29                                                 if   \n",
      "...            ...     ...                                                ...   \n",
      "227418      362177  362177                                      edward-kelley   \n",
      "227419      362178  362178                                   the-moon-exalted   \n",
      "227420      362179  362179                                the-marvelous-dream   \n",
      "227421      362181  362181                                             saturn   \n",
      "227422      362182  362182                                           a-prayer   \n",
      "227423      362183  362183                                   a-man-of-england   \n",
      "227424      362185  362185                                        apple-carts   \n",
      "227425      362194  362194                                   sunset-coming-in   \n",
      "227426      362203  362203                    the-history-of-a-cheating-heart   \n",
      "227427      362204  362204                                  lonely-press-play   \n",
      "227428      362205  362205                                           mr-tembo   \n",
      "227429      362208  362208                                    everyday-robots   \n",
      "227430      362209  362209                                 heavy-seas-of-love   \n",
      "227431      362210  362210                     photographs-you-are-taking-now   \n",
      "227432      362211  362211                                         you-and-me   \n",
      "227433      362212  362212                                       hollow-ponds   \n",
      "227434      362213  362213                                  the-selfish-giant   \n",
      "227435      362214  362214                                           hostiles   \n",
      "227436      362225  362225              can-t-you-see-that-you-are-killing-me   \n",
      "227437      362226  362226                          you-ll-never-know-my-name   \n",
      "227438      362227  362227                                too-good-to-be-true   \n",
      "227439      362228  362228                                      skinny-dippin   \n",
      "227440      362229  362229                                         cherry-pie   \n",
      "227441      362230  362230                                      feels-so-real   \n",
      "227442      362231  362231                                       swingin-door   \n",
      "227443      362232  362232                          who-am-i-drinking-tonight   \n",
      "227444      362233  362233                                               liar   \n",
      "227445      362234  362234                                        last-supper   \n",
      "227446      362235  362235                        christ-alone-live-in-studio   \n",
      "227447      362236  362236                                               amen   \n",
      "\n",
      "        year           artist    genre  \\\n",
      "0       2009  beyonce-knowles      Pop   \n",
      "1       2009  beyonce-knowles      Pop   \n",
      "2       2009  beyonce-knowles      Pop   \n",
      "3       2009  beyonce-knowles      Pop   \n",
      "4       2009  beyonce-knowles      Pop   \n",
      "5       2009  beyonce-knowles      Pop   \n",
      "6       2009  beyonce-knowles      Pop   \n",
      "7       2009  beyonce-knowles      Pop   \n",
      "8       2009  beyonce-knowles      Pop   \n",
      "9       2009  beyonce-knowles      Pop   \n",
      "10      2009  beyonce-knowles      Pop   \n",
      "11      2009  beyonce-knowles      Pop   \n",
      "12      2009  beyonce-knowles      Pop   \n",
      "13      2009  beyonce-knowles      Pop   \n",
      "14      2009  beyonce-knowles      Pop   \n",
      "15      2009  beyonce-knowles      Pop   \n",
      "16      2009  beyonce-knowles      Pop   \n",
      "17      2007  beyonce-knowles      Pop   \n",
      "18      2007  beyonce-knowles      Pop   \n",
      "19      2007  beyonce-knowles      Pop   \n",
      "20      2007  beyonce-knowles      Pop   \n",
      "21      2007  beyonce-knowles      Pop   \n",
      "22      2007  beyonce-knowles      Pop   \n",
      "23      2007  beyonce-knowles      Pop   \n",
      "24      2007  beyonce-knowles      Pop   \n",
      "25      2007  beyonce-knowles      Pop   \n",
      "26      2007  beyonce-knowles      Pop   \n",
      "27      2007  beyonce-knowles      Pop   \n",
      "28      2007  beyonce-knowles      Pop   \n",
      "29      2007  beyonce-knowles      Pop   \n",
      "...      ...              ...      ...   \n",
      "227418  2012     damon-albarn      Pop   \n",
      "227419  2012     damon-albarn      Pop   \n",
      "227420  2012     damon-albarn      Pop   \n",
      "227421  2012     damon-albarn      Pop   \n",
      "227422  2012     damon-albarn      Pop   \n",
      "227423  2012     damon-albarn      Pop   \n",
      "227424  2012     damon-albarn      Pop   \n",
      "227425  2015     damon-albarn      Pop   \n",
      "227426  2014     damon-albarn      Pop   \n",
      "227427  2014     damon-albarn      Pop   \n",
      "227428  2014     damon-albarn      Pop   \n",
      "227429  2014     damon-albarn      Pop   \n",
      "227430  2014     damon-albarn      Pop   \n",
      "227431  2014     damon-albarn      Pop   \n",
      "227432  2014     damon-albarn      Pop   \n",
      "227433  2014     damon-albarn      Pop   \n",
      "227434  2014     damon-albarn      Pop   \n",
      "227435  2014     damon-albarn      Pop   \n",
      "227436  2015         dee-smgn    Other   \n",
      "227437  2015         dee-smgn    Other   \n",
      "227438  2012       edens-edge  Country   \n",
      "227439  2012       edens-edge  Country   \n",
      "227440  2012       edens-edge  Country   \n",
      "227441  2012       edens-edge  Country   \n",
      "227442  2012       edens-edge  Country   \n",
      "227443  2012       edens-edge  Country   \n",
      "227444  2012       edens-edge  Country   \n",
      "227445  2012       edens-edge  Country   \n",
      "227446  2012       edens-edge  Country   \n",
      "227447  2012       edens-edge  Country   \n",
      "\n",
      "                                                   lyrics  \n",
      "0       Oh baby  how you doing \\nYou know I'm gonna cu...  \n",
      "1       playin everything so easy \\nit's like you seem...  \n",
      "2       If you search\\nFor tenderness\\nIt isn't hard t...  \n",
      "3       Oh oh oh I  oh oh oh I\\n \\nIf I wrote a book a...  \n",
      "4       Party the people  the people the party it's po...  \n",
      "5       I heard\\nChurch bells ringing\\nI heard\\nA choi...  \n",
      "6       This is just another day that I would spend\\nW...  \n",
      "7       Waiting  waiting  waiting  waiting\\nWaiting  w...  \n",
      "8        \\nI read all of the magazines\\nwhile waiting ...  \n",
      "9       N n now  honey\\nYou better sit down and look a...  \n",
      "10      I lay alone awake at night\\nSorrow fills my ey...  \n",
      "11      Hello hello baby you called\\nI can't hear a th...  \n",
      "12      Feels like I'm losing my mind\\nLove is so hard...  \n",
      "13      Youre everything I thought you never were\\nAnd...  \n",
      "14      I gotta give up\\nto quite the storm that rages...  \n",
      "15      It really hurts to say this yes it does\\nBut a...  \n",
      "16      You're bad for me I clearly get it\\nI don't se...  \n",
      "17       \\nI'm a world wide woman WWW you can log on a...  \n",
      "18      Ay\\nAy\\nAy  Nobody likes to be played \\nOh  Be...  \n",
      "19      Ay  Ay \\n Nobody likes being played \\nAy \\nOh ...  \n",
      "20      Ay  Ay \\n Nobody likes being played \\nAy \\nOh ...  \n",
      "21      Beyonc   Intro \\nBeyonce\\nIAM\\nWelcome\\nWelcom...  \n",
      "22      Ay  Ay \\n Nobody likes being played \\nAy \\nOh ...  \n",
      "23      Took me a while but I'm finally here\\nSo I jus...  \n",
      "24      Ay  Ay  Ay \\nOh  Beyonc  Beyonc\\nOh  Beyonc  B...  \n",
      "25      To the left  to the left\\nTo the left  to the ...  \n",
      "26      Remember the first day when I saw your face\\nr...  \n",
      "27      you say that he's wrong\\nyou say that he's no ...  \n",
      "28      1st verse \\nhey you what's the deal  its poppi...  \n",
      "29      He is always laughin and flirting with me\\nAnd...  \n",
      "...                                                   ...  \n",
      "227418  I must cry\\nI am a  wonder us house\\nI am the ...  \n",
      "227419  To love another \\nWould it mean my heart\\nLet ...  \n",
      "227420  Hurricane spitting tornado\\nGrowl over London ...  \n",
      "227421  I summon the voice of distance stars\\nSaturn s...  \n",
      "227422  Lord I have sight according to thy choice\\nmy ...  \n",
      "227423  Hurricane spitting tornado\\nGrowl over London ...  \n",
      "227424  Pull the apple carts\\nUp from silvery hill\\nHi...  \n",
      "227425  Waking up\\nIt's been too long\\nFeel the warmth...  \n",
      "227426  More than you know\\nMore than you know\\nWhen t...  \n",
      "227427  Arrhythmia\\nAccepting that you live with uncer...  \n",
      "227428  Injili  Injili\\nCan I sing with you\\n'Bout Mr ...  \n",
      "227429  We are everyday robots on our phones\\nIn the p...  \n",
      "227430  When your soul isn't right\\nAnd it's raw to th...  \n",
      "227431  When the photographs you're taking now\\nAre ta...  \n",
      "227432  I met Moko jumbie \\nHe walks on stilts through...  \n",
      "227433  Chill on the hollow ponds\\nSet sail by a kid\\n...  \n",
      "227434  Celebrate the passing drugs\\nPut them on the b...  \n",
      "227435  When the serve is done\\nAnd the parish shuffle...  \n",
      "227436  Days getting dark and the nights are growing c...  \n",
      "227437  You'll never know my name\\nAnd my pictures wil...  \n",
      "227438  You walked in shining brighter than a headligh...  \n",
      "227439  I warned you that the tank was low\\nShoulda st...  \n",
      "227440  To my first pony  Cherry Pie\\nFrom the little ...  \n",
      "227441  It was two years ago and it was yesterday\\nIt ...  \n",
      "227442  You've got your Texas way of walking \\nYou've ...  \n",
      "227443  I gotta say\\nBoy  after only just a couple of ...  \n",
      "227444  I helped you find her diamond ring\\nYou made m...  \n",
      "227445  Look at the couple in the corner booth\\nLooks ...  \n",
      "227446  When I fly off this mortal earth\\nAnd I'm meas...  \n",
      "227447  I heard from a friend of a friend of a friend ...  \n",
      "\n",
      "[227448 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "numpy_data = data['lyrics'].values\n",
    "max_words = 5000\n",
    "\n",
    "# cols: index, song, year, artist, genre, lyrics\n",
    "# N = 227449 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Tokenizer\n",
    "tokenizer = text.Tokenizer(num_words=max_words, oov_token='<UNK>')\n",
    "# feed our tweets to the Tokenizer\n",
    "tokenizer.fit_on_texts(numpy_data)\n",
    "\n",
    "# Tokenizers come with a convenient list of words and IDs\n",
    "dictionary = tokenizer.word_index\n",
    "\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_LINES = 60\n",
    "MAX_WORDS_PER_LINE = 10 # both parameters copied from Tsaptsinos\n",
    "\n",
    "def get_indexed_data():\n",
    "    indexed_data = []\n",
    "    # for each tweet, change each token to its ID in the Tokenizer's word_index\n",
    "    for txt in numpy_data:\n",
    "        wordIndices = [dictionary[word] for word in text.text_to_word_sequence(txt)]\n",
    "        indexed_data.append(wordIndices)\n",
    "\n",
    "    # now we have a list of all tweets converted to index arrays.\n",
    "    # cast as an array for future usage.\n",
    "    indexed_data = np.asarray(indexed_data)\n",
    "    return indexed_data\n",
    "def get_indexed_data_by_line():\n",
    "#     # Use this zero vector when padding lines.\n",
    "    zero_line_vector = MAX_WORDS_PER_LINE*[max_words+1]\n",
    "    indexed_data = []\n",
    "    for txt in numpy_data:\n",
    "        lines = txt.split(\"\\n\")\n",
    "        wordIndices = []\n",
    "        for line in lines:\n",
    "            wordIndicesOnLine = [dictionary[word] for word in text.text_to_word_sequence(line)]\n",
    "            wordIndices.append(wordIndicesOnLine)\n",
    "        song_padded = wordIndices[:MAX_NUM_LINES] + (MAX_NUM_LINES-len(wordIndices)) * [zero_line_vector]\n",
    "        padded = sequence.pad_sequences(song_padded, maxlen=MAX_WORDS_PER_LINE)\n",
    "        indexed_data.append(padded) \n",
    "    \n",
    "    # now we have a list of all tweets converted to index arrays.\n",
    "    # cast as an array for future usage.\n",
    "    indexed_data = np.stack(indexed_data, axis = 0)#np.asarray(indexed_data)\n",
    "    return indexed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0   39   61   74    3  517]\n",
      " [   0    3   27   15   81  534   80    4    1 1279]\n",
      " [   0    0    0  105  928  139  184   24    7  247]\n",
      " [   4  110   13    2   49 2382   18    6  967 2581]\n",
      " [   3   27  257   87  967  159    3    3   78    7]\n",
      " [   0    0    0    0   30   14   61  218   40  210]\n",
      " [  22   86    4  173  146  335  100   51    1 1454]\n",
      " [  18  205   56    3    4  195    7   74    3   78]\n",
      " [   0    0    2 3500  247 1016   99    6  231  910]\n",
      " [   0  111  125    3   38    1 1007    4    8   90]\n",
      " [  81   86   10  203  790    3  322   32    8  316]\n",
      " [   0    5  195    7 1425    3  285   27   49  187]\n",
      " [   0    0    0    0   28   86   18    7    4  355]\n",
      " [   0    0    0    0   30  102  231   30  102  765]\n",
      " [   0    0    0    0   30  102  428   10  127 1083]\n",
      " [   0    0    0    0   30  102  163   30  102 1192]\n",
      " [  73  278   25   29  100   73   37   65   10   32]\n",
      " [   0   73   38    6  231 2758  488    6 5781 2758]\n",
      " [   0    0    2   26  118  231 2758   30  102  163]\n",
      " [  73  224   25   29  100   73   37   65   10   32]\n",
      " [   0    0 3280   15 3555   80   35    2   22  931]\n",
      " [  37  170   23    7   97    3   89   57    1  746]\n",
      " [   0    0  105  173   10 8615    2  173   10 7148]\n",
      " [   3 1517   33    3  137   14   34   15  907   23]\n",
      " [   0  459    2   27   15  896    3   23  121 1364]\n",
      " [   0    0    0    0    0    0  151  556  121 3276]\n",
      " [ 383    6 1026   30    8  373   97  269    8  119]\n",
      " [   3    6 5835    4   48  415   11  174   25    7]\n",
      " [   0    0    0    0   30  102  231   30  102  765]\n",
      " [   0    0    0    0   30  102  428   10  127 1083]\n",
      " [   0    0    0    0   30  102  163   30  102 1192]\n",
      " [   2  278   25   29  100    2   37   65   10   32]\n",
      " [   0    2   38    6  231 2758  488    6 5781 2758]\n",
      " [   0   24   73   26    8  231 2758   30  102  163]\n",
      " [   2  224   25   29  100    2   37   65   10   32]\n",
      " [   2  224   25   29  100    2   37   65   10   32]\n",
      " [   2  278   25   29  100    2   37   65   10   32]\n",
      " [   2   37   65   10   32    2   37   65   10   32]\n",
      " [   2  224   25   29  100    2   37   65   10   32]\n",
      " [   0    0    0    0   30  102  231   30  102  765]\n",
      " [   0    0    0    0   30  102  428   10  127 1083]\n",
      " [   0    0    0    0   30  102  163   30  102 1192]\n",
      " [  73  278   25   29  100   73   37   65   10   32]\n",
      " [ 231 2758  488    6 5781 2758  488    6 5781 2758]\n",
      " [   0    0    2   26  118  231 2758   30  102  163]\n",
      " [  73  224   25   29  100   73   37   65   10   32]\n",
      " [   0    0    0    0 2758   21  231    3  268 1641]\n",
      " [   2   38  126  462    4   78   25   15   13  251]\n",
      " [   0    0    0 2758   21  428   42    3   85   27]\n",
      " [  22   86   28  370    2   37  302   10   23 3056]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]\n",
      " [5001 5001 5001 5001 5001 5001 5001 5001 5001 5001]]\n"
     ]
    }
   ],
   "source": [
    "indexed_data = get_indexed_data_by_line()\n",
    "print(indexed_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227448, 60, 10) (60, 10)\n",
      "[[     0      0      0      0      0      0    528    201     82   1383]\n",
      " [     0      0      0      0      0      0    528    201     82   1383]\n",
      " [     0      0      0      0      0      0    528    201     82   1383]\n",
      " [     0      0      0      0      0      0    528    201     82   1383]\n",
      " [     0      0      0      0      0      0    528    201     82   1383]\n",
      " [     0      0      0      0      0      0      0      0    218     44]\n",
      " [     0      0      0   1226      4      1    370    200    250     32]\n",
      " [     0      0      0      0    320      9      1    208    259     32]\n",
      " [     0      0      5    741     10    471     10    954      1    712]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     5    113    145      3     37     36      4    153    201    141]\n",
      " [     0      0      5     33      1    445    928     19   2262    141]\n",
      " [     0    138    385      4    100      6   2626      9     29    403]\n",
      " [     0      0    309     20    154      1    248   9536    197    141]\n",
      " [     0      0      0      0      0      0     20     38    201    664]\n",
      " [     0     36     20    162     38    121     16      9      6   4325]\n",
      " [     0      0      0      0      0      0      0      0      0 161571]\n",
      " [     0      0      0      0      0      0     20     38    201    664]\n",
      " [     0     36     20    162     38    121     16      9      6   4325]\n",
      " [     0      0      0      0      0      0      0      0      0  91818]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0   1662     46      2     60      9]\n",
      " [     0      0      0      0      5      2   3002     14      1    244]\n",
      " [     0      0      0      0      0      5     20   1848      1   2568]\n",
      " [    21      2    271      3     27     20     38     95    183     14]\n",
      " [     0      0    100      3    152     27     13     33     20     40]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0     85    152   1120     42      3    152    926]\n",
      " [     0      0      5    437    201     32    104     10      4    201]\n",
      " [     0      0      0     67    121     32     67      7     36    121]\n",
      " [     0      0      0   1873    185   2013      5     67     10    985]\n",
      " [     0      0      0      0      0      0     40     12   1085     14]\n",
      " [     0      0      0      0      0      0    320     40    334     35]\n",
      " [     0      0      0      0   1662      2     36     34      2     36]\n",
      " [     0      0      0      0      0      0      0      0    954  31323]\n",
      " [     0      0      0      0      0     68      1    200    101    926]\n",
      " [   218     44    100      3     27     20  17860    314  17860    314]\n",
      " [     0      0      0      0      0      0      0      0      0     40]\n",
      " [     0      0      0      0      0      0      0    320     40     40]\n",
      " [     2    101     48     16      6      8    200   1693      6    354]\n",
      " [     0     42    142     23      7    101     48    142     31    926]\n",
      " [     0      0      0      0      0      0     23  47306      5  65883]\n",
      " [     0      0      0      0     20    103      4   2428      6  22996]\n",
      " [     0      0      0      0      0     35     40     12    712     14]\n",
      " [     0      0      5      8    200    162    492      7    107    926]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0    218    528    201     82   1383]\n",
      " [     0      0      0      0      0    218    528    201     82   1383]\n",
      " [     0      0      0      0      0    218    528    201     82   1383]\n",
      " [     0      0      0      0      0    218    528    201     82   1383]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0     20     38    201   3683]]\n",
      "60\n",
      "Catch Em By Surprise\n",
      "Catch Em By Surprise\n",
      "Catch Em By Surprise\n",
      "Catch Em By Surprise\n",
      "Catch em by surprise    \n",
      "Let's go\n",
      "Bounce to the beat  people hands up\n",
      "Everybody in the place stand up\n",
      "And jump it  shake it  bust the club\n",
      " \n",
      "And there's nothing you can do to hold em off\n",
      "And when the beautiful women be showing off\n",
      "We're bout to cause a riot in this house\n",
      "Till we hear the fire alarms going off\n",
      "We got em watching\n",
      "Do we really got them all in a trance \n",
      " Aoooww \n",
      "We got em watching\n",
      "Do we really got them all in a trance \n",
      " Aoowww \n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      " \n",
      "Everytime time I come in\n",
      "And I stumble on the feeling\n",
      "And we lit the fires\n",
      "So I hope you know we got our run on\n",
      "Cause you gotta know that when we get\n",
      " \n",
      "Ain't gotta question if you gotta  C'mon \n",
      "And hurt em up  Give it to em \n",
      "Let them up  Let me do them \n",
      "Spark another match and let it flame\n",
      "Get your dumb on \n",
      "Everybody get ready now\n",
      "Everytime I do what I do\n",
      "Bust ryhmes\n",
      "Make the people wanna  C'mon \n",
      "Let's go cause you know we go'n fly  Go'n fly \n",
      "Get  \n",
      "Everybody get  get\n",
      "Now I wanna see all a my people form a line\n",
      "If ya with me wanna see ya just  C'mon \n",
      "With Diplo and Tiesto\n",
      "We about to create a fiasco\n",
      "Now get your club on\n",
      "And my people really wit me then  C'mon \n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      " \n",
      "Let's catch em by surprise\n",
      "Let's catch em by surprise\n",
      "Let's catch em by surprise\n",
      "Let's catch em by surprise\n",
      " \n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "We got em hypnotized\n",
      "[ \n",
      "316\n",
      "47306\n"
     ]
    }
   ],
   "source": [
    "print (indexed_data.shape, indexed_data[1].shape)\n",
    "print(indexed_data[133643])\n",
    "print(len(indexed_data[133643]))\n",
    "print(data['lyrics'][133643])\n",
    "print(len(data['lyrics'][133643].split()))\n",
    "print(dictionary['diplo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max lyric length is 6208 at song #9467\n",
    "#top 10 lyric lengths: [5131 4287 6208 3278 3167 3155 3153 2997 2750 2660]\n",
    "#for top 1000 lengthiest songs, even first 1000 words seems sufficient\n",
    "#for top 100 lengthiest songs, first 1500 words seems sufficient\n",
    "#np.max(np.vectorize(len)(indexed_data))\n",
    "#temp = np.partition(-np.vectorize(len)(indexed_data), 100)\n",
    "#result_args = temp[:100]\n",
    "\n",
    "label_encoder = skpp.LabelEncoder()\n",
    "indexed_labels = np.array(label_encoder.fit_transform(data['genre'].values))\n",
    "assert indexed_labels.shape[0] == indexed_data.shape[0]\n",
    "#label_encoder.inverse_transform(np.array([10, 8])) #to get original genre text back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 30000\n",
    "\n",
    "#shuffle data before splitting off test set\n",
    "random_indexes = np.random.permutation(len(indexed_labels))\n",
    "indexed_data = indexed_data[random_indexes]\n",
    "indexed_labels = indexed_labels[random_indexes]\n",
    "\n",
    "X_train = indexed_data[:-num_test]\n",
    "y_train = indexed_labels[:-num_test]\n",
    "X_test  = indexed_data[-num_test:]\n",
    "y_test  = indexed_labels[-num_test:]\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size = 336097\n",
    "num_words = max_words + 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/alexTsaptsinos/lyricsHAN/blob/master/code/models/HANkeras.py\n",
    "attention_size = 100 # size of hidden layer output from word attention\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.hidden_dim = attention_size\n",
    "        super(AttLayer,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='kernel', shape=(input_shape[-1], self.hidden_dim), initializer = 'he_normal', trainable=True)\n",
    "        self.bw = self.add_weight(name='bias', shape=(self.hidden_dim,), initializer = 'zero', trainable=True)\n",
    "        self.uw = self.add_weight(name='uw', shape=(self.hidden_dim,), initializer = 'he_normal', trainable=True)\n",
    "        self.trainable_weights = [self.W, self.bw, self.uw]\n",
    "        super(AttLayer,self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x_reshaped = tf.reshape(x, [K.shape(x)[0]*K.shape(x)[1], K.shape(x)[-1]])\n",
    "        ui = K.tanh(K.dot(x_reshaped, self.W) + self.bw)\n",
    "        intermed = tf.reduce_sum(tf.multiply(self.uw, ui), axis=1)\n",
    "\n",
    "        weights = tf.nn.softmax(tf.reshape(intermed, [K.shape(x)[0], K.shape(x)[1]]), dim=-1)\n",
    "        weights = tf.expand_dims(weights, axis=-1)\n",
    "\n",
    "        weighted_input = x*weights\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_16 (TimeDis (None, 60, 100)           195164    \n",
      "_________________________________________________________________\n",
      "bidirectional_39 (Bidirectio (None, 60, 100)           45300     \n",
      "_________________________________________________________________\n",
      "att_layer_29 (AttLayer)      (None, 100)               10200     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 11)                1111      \n",
      "=================================================================\n",
      "Total params: 251,775\n",
      "Trainable params: 251,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[3566,9] = 95163 is not in [0, 5002)\n\t [[Node: time_distributed_16/embedding_33/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_33/embeddings/read, time_distributed_16/embedding_33/Cast)]]\n\nCaused by op 'time_distributed_16/embedding_33/Gather', defined at:\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-92-1d31529cc30c>\", line 14, in <module>\n    model.add(TimeDistributed(sentence_model, input_shape=(MAX_NUM_LINES, MAX_WORDS_PER_LINE)))\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/models.py\", line 467, in add\n    layer(x)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/layers/wrappers.py\", line 211, in call\n    y = self.layer.call(inputs, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/models.py\", line 549, in call\n    return self.model.call(inputs, mask)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1211, in gather\n    return tf.gather(reference, indices)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1864, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[3566,9] = 95163 is not in [0, 5002)\n\t [[Node: time_distributed_16/embedding_33/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_33/embeddings/read, time_distributed_16/embedding_33/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[3566,9] = 95163 is not in [0, 5002)\n\t [[Node: time_distributed_16/embedding_33/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_33/embeddings/read, time_distributed_16/embedding_33/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-1d31529cc30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[3566,9] = 95163 is not in [0, 5002)\n\t [[Node: time_distributed_16/embedding_33/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_33/embeddings/read, time_distributed_16/embedding_33/Cast)]]\n\nCaused by op 'time_distributed_16/embedding_33/Gather', defined at:\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-92-1d31529cc30c>\", line 14, in <module>\n    model.add(TimeDistributed(sentence_model, input_shape=(MAX_NUM_LINES, MAX_WORDS_PER_LINE)))\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/models.py\", line 467, in add\n    layer(x)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/layers/wrappers.py\", line 211, in call\n    y = self.layer.call(inputs, **kwargs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/models.py\", line 549, in call\n    return self.model.call(inputs, mask)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/engine/topology.py\", line 2236, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1211, in gather\n    return tf.gather(reference, indices)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2585, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1864, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Users/connor/anaconda2/envs/194py35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[3566,9] = 95163 is not in [0, 5002)\n\t [[Node: time_distributed_16/embedding_33/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_33/embeddings/read, time_distributed_16/embedding_33/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "# # create the layered GRU model\n",
    "\n",
    "embedding_vector_length = 32\n",
    "hidden_size = 50 # from Tsaptsinos\n",
    "dropout = .5\n",
    "\n",
    "sentence_model = Sequential()\n",
    "sentence_model.add(Embedding(num_words, embedding_vector_length, input_shape=(MAX_WORDS_PER_LINE,)))\n",
    "sentence_model.add(Bidirectional(GRU(hidden_size, return_sequences=True)))\n",
    "sentence_model.add(AttLayer())\n",
    "sentence_model.add(Dropout(.5))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(sentence_model, input_shape=(MAX_NUM_LINES, MAX_WORDS_PER_LINE)))\n",
    "model.add(Bidirectional(GRU(hidden_size, return_sequences=True)))\n",
    "model.add(AttLayer())\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, nb_epoch=1, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test_padded, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
